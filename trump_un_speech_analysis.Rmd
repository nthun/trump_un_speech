---
title: "R Notebook"
output: html_notebook
---

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(rvest)
library(tidytext)
library(forcats)
library(wordcloud)
library(wordcloud2)
library(rworldmap)
library(stringr)
library(ggrepel)
```

```{r}
url <- "http://www.politico.com/story/2017/09/19/trump-un-speech-2017-full-text-transcript-242879"
speech_excerpt <- 
        read_html(url) %>% # Download whole homepage
        html_nodes("style~ p+ p , .lazy-load-slot+ p , .fixed-story-third-paragraph+ p , .story-related+ p , p~ p+ p") %>% # Select the required elements (by css selector)
        html_text() %>% # Make it text
        .[-2] %>% # Remove some random homepage text
        gsub("Mr.", "Mr", ., fixed = T) %>% # Make sure that dots in the text will not signify sentences
        gsub("United States of America", "usa", .) %>% # USA has to be preserved as one expression
        gsub("United States", "usa", .) %>% 
        gsub("America", "usa", .) %>% 
        gsub("States", "usa", .) %>% 
        gsub("North Korea", "north_korea", .) %>% # North Korea should be preserved as one word for now
        data_frame(paragraph = .)
                        
speech_sentences <- 
        speech_excerpt %>% 
        unnest_tokens(sentence, paragraph, token = "sentences")
        
speech_words <- 
        speech_excerpt %>% 
        unnest_tokens(word, paragraph, token = "words") %>% 
        mutate(word = gsub("_", " ", word))
```


```{r fig.height=10, fig.width=10, message=FALSE, warning=FALSE}
speech_words %>% 
        anti_join(stop_words, by = "word") %>% 
        count(word, sort = TRUE) %>% 
        wordcloud2()
        # wordcloud2(figPath = "trump.png") # Image downloaded from http://westviewnews.org/wp-content/uploads/2017/01/donald-trump-profile-silhouette-vector-graphic_template_1469623874993O0L.png
```


```{r fig.width=10}
# Check emotional words that were uttered at least 3 times
speech_words %>% 
        count(word, sort = TRUE) %>% 
        inner_join(get_sentiments("bing"), by = "word") %>% 
        filter(n > 3) %>% 
        mutate(n = if_else(sentiment == "negative", -n, n)) %>% 
        ggplot() +
                aes(y = n, x = fct_reorder(word, n), fill = sentiment) +
                geom_col() +
                coord_flip() +
                labs(x = "word", y ="Occurance in speech") +
                ggtitle("Most common words in Trump's 17/09/19 UN speech by sentiment")


```
# Comparison cloud of all words
```{r fig.height=10, fig.width=10}
speech_words %>%
        inner_join(get_sentiments("bing"), by = "word") %>% 
        count(word, sentiment, sort = TRUE) %>%
        spread(sentiment, n, fill = 0L) %>%
        as.data.frame() %>% 
        remove_rownames() %>% 
        column_to_rownames("word") %>% 
        comparison.cloud(colors = c("red", "blue"))
```

# Let's look into specific emotions using the nrc sentiment dictionary

First, look at the words associated with distinct emotions in the whole speech.

```{r}
speech_words %>%
        inner_join(get_sentiments("nrc"), by = "word") %>% # Use distinct emotion dictionary
        filter(!sentiment %in% c("positive","negative")) %>% # Only look for distinct emotions
        group_by(sentiment) %>% 
        count(sentiment, sort = T) %>% 
        ggplot() +
                aes(x = fct_reorder(sentiment %>% str_to_title, -n), y = n, label = n) +
                geom_col() +
                geom_label(vjust = 1) +
                theme_minimal() +
                labs(title = "The occurance of words linked to distinct emotions in the speech", x = "Word", y = "Frequency")
```



```{r}
# Load map database
map_world <- 
        map_data(map="world") %>% 
        mutate(region = region %>% str_to_lower()) # Make country name lower case to match word

# Calculate mentions of a country, and join geodata
trump_countries <-
        speech_words %>% 
        count(word) %>% 
        right_join(map_world, by = c("word" = "region")) %>% # Match country coordinates to speech
        select(region = word, everything())

# Get country names with the middle of the country coordinates
country_names <- 
        trump_countries %>% 
        drop_na(n) %>%
        group_by(region) %>% 
        summarise(lat = mean(lat),
                  long = mean(long))

# Countries mentioned in the speech and frequency
trump_countries %>% 
        drop_na(n) %>% 
        group_by(region) %>% 
        slice(1) %>% 
        ungroup() %>% 
        select(country = region, n) %>% 
        mutate(country = country %>% str_to_title()) %>% 
        arrange(-n) %>% 
        ggplot() +
                aes(x = fct_reorder(country, n), y = n) +
                geom_col() +
                coord_flip() +
                theme_minimal() +
                labs(title = "Mentions of a country", y = "Mentions", x = "Country")

```
# Map countries with the number of mentions (USA excluded)

```{r fig.width=10, message=FALSE, warning=FALSE}
trump_countries %>% 
        mutate(n = if_else(region == "usa", NA_integer_, n)) %>%
ggplot() +
        aes(map_id = region, x = long, y = lat, fill = n, label = region %>% str_to_title()) +
        geom_map(map = trump_countries) +
        # geom_text(data = trump_countries %>% drop_na(n) %>% group_by(region) %>% slice(1)) +
        scale_fill_gradient(low = "lightblue", high = "darkblue", na.value = "grey90") +
        theme_minimal() +
        labs(title = "Number of mentions by country (USA excluded)", x = "Longitude", y = "Latitude")


```

```{r}
# Sentiment of each sentence
sentence_sentiment <-
        speech_sentences %>% 
        mutate(sentence_num = row_number(),
               sentence_length = length(sentence)
               ) %>% 
        unnest_tokens(word, sentence, "words") %>% 
        mutate(word = gsub("_", " ", word)) %>% 
        left_join(get_sentiments("bing"), by = "word") %>% 
        mutate(sentiment_score = case_when(sentiment == "positive" ~ 1,
                                           sentiment == "negative" ~ -1,
                                           is.na(sentiment) ~ NA_real_)) %>% 
        group_by(sentence_num) %>%
        summarise(sum_sentiment = sum(sentiment_score, na.rm = T),
                  sentiments = paste(word, collapse = ", "))

# Which sentence has a country name
country_sentence <- 
        speech_sentences %>% 
        mutate(sentence_num = row_number()) %>% 
        unnest_tokens(word, sentence, "words") %>% 
        mutate(word = gsub("_", " ", word)) %>% 
        right_join(country_names %>% select(region), by = c("word" = "region")) %>% 
        arrange(sentence_num)

# Sentiment for each country
country_sentiment <-         
        sentence_sentiment %>% 
        full_join(country_sentence, by = "sentence_num") %>% 
        select(region = word, sum_sentiment) %>% 
        drop_na() %>% 
        group_by(region) %>% 
        summarise(country_sentiment = sum(sum_sentiment))

```

```{r fig.width=10, message=FALSE, warning=FALSE}
sentence_sentiment %>% 
        full_join(country_sentence) %>% 
        mutate(sentiment_type = case_when(sum_sentiment >0 ~ "positive",
                                         sum_sentiment <0 ~ "negative")) %>% 
        ggplot() +
                aes(x = sentence_num, y = sum_sentiment) +
                geom_hline(yintercept = 0, color = "black", linetype = "dashed", size = 1.2) +
                geom_line() +
                geom_label_repel(aes(label = word %>% str_to_title(), fill = sentiment_type)) +
                theme_minimal() +
                labs(title = "The appearance of country names in the speech by sentiment in sentence order", x = "Sentence number", y = "Summarised sentiment")

```


```{r fig.width=10, message=FALSE, warning=FALSE}
trump_countries %>% 
        left_join(country_sentiment) %>% 
        mutate(country_sentiment = if_else(region == "usa", NA_real_, country_sentiment)) %>% 
        ggplot() +
                aes(map_id = region, x = long, y = lat, fill = country_sentiment, label = region %>% str_to_title()) +
                geom_map(map = trump_countries) +
                scale_fill_gradient(high = "green", low = "red", guide = "colourbar", na.value = "grey90") +
                theme_minimal() +
                labs(title = "Sentiment of the sentences where countries were mentioned (USA excluded)", x = "Longitude", y = "Latitude")

```

